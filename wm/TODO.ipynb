{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+detrended - dołożyć do dataframe - jest różnica logarytmów\n",
    "-detrended - rozważyć inne podejście:\n",
    "    - przejść na procenty\n",
    "    + zamiast zawsze robić różnicę między aktualną a historyczną wartością - od wszystkich wartości w oknie odjąć wartość z           początku okna\n",
    "        + to dorobiłem do fourier i sine - choć wartości wyszły inne niż te przed wirusem\n",
    "    - użyć lindear regresion do wyznaczenia trendu(linni) (rolling trend over window) - odjąć wartości waluty od prostej trendu \n",
    "+dodać feature GARCH - w pdfie ARCE05 - punkt 3.2\n",
    "+sprawdzić z użyciem MT4 czy inicatory napisane w python dają dobre wyniki\n",
    "+dodac wskaźnik Weighted Closing Price (WPC)\n",
    "+dodać wskaźniki  \n",
    "    + High, low average periods = 1,2\n",
    "    + Trading day price average(O+H+C+L)/4 - period=1\n",
    "    + uwzględnić Volume\n",
    "    \n",
    "- PNP - wzkaźnik mierzenia sukcesu - jak to włączyć do modelu uczącego się aby uzględniał to zamiast zwykłego procentu trafień?\n",
    "                                    - nie da się tak. PNP można użyć aby porównać modele\n",
    "\n",
    "+ dodać do featurów (jako kolumny binarne 0,1:\n",
    "    +numer miesiąca\n",
    "    +numer dnia tygodnia\n",
    "    +numer dnia miesiąca\n",
    "- dodać sumsum change_pct ale specjalnie napisane (np. przy 10,12,10,15,10 powinnyśmy otrzymać: 0,20,0,50,0 a nie 0,20,20-16,20-16+50,20-16+50-33 czyli 0,20,4,54,21\n",
    "+ slopy na histogramach (różnica między linią indicatora a linią signal)\n",
    "- być może dodać nowy feature do histogramów - czy przecięło zero: 0 nie, 1 tak(z dołu),-1 tak (z góry) - pewnie lepiej byłoby 3 binarne kolumny\n",
    "- dodać nowy magiczny wskaźnić - siła najbliższych poziomów - na kartce.\n",
    "+ dodać wartości historyczne jako nowe kolumny, Daily, weekly, monthly\n",
    "+ bibliteki i kursy FastAI: https://www.fast.ai/\n",
    "+ dla GARCH i ARIMA - dane na których się uczy powinny chyba być po kolei (go to jest time series method)\n",
    "    - uczenie garch arima, jest w ramach feature selection a tam jest po kolei.\n",
    "+ poprawić błąd w MLP - jest na stałe ([10,10]\n",
    "- uwzględnić Volume\n",
    "- uwzględnić więcej parametrów w MLP - learning rate itp.\n",
    "+ zrobiłem porównanie feature_collection pre i post. Post jest minimalne lepsze na tym jednem przykładzie (pca15SVC):zmieniłem data split na shuffle=False, dostosowałem wielkość datasetu w obu przypadkach. Zakomentowałem replace NaN na zera w fourier i sine\n",
    "       Pytanie czy robimy\n",
    "          - zapuszczenie całości na azure pre z nowym datasplitem\n",
    "          - zapuszczenie całości na azure post z nowym splitem i nowym datasetem\n",
    "          - są nadal różnice między datasetami, bo w wersji pre są nulle na fourier tam gdzie w post nie na nulli\n",
    "          ZAKOŃCZONE\n",
    "- dorzucić dodatkową miarę - loss (tak jak jest w fastai)\n",
    "- można podstroić parametry feature selection np. dla SVC - kernel, gamma, C \n",
    "\n",
    "POMYSŁY:\n",
    "- jak wybrać (zdefiniować) podzbiór obserwacji dla którego wyniki są dobre(lepsze)\n",
    "+ SL low minus atr, TP high plus atr, distanse nieskończony,\n",
    "+ czy to jest dobrze że dodaje usuwam atr - co to jest atr? - jest OK\n",
    "+ czy używać atr (średnia z ostatnich 14) czy może użyć średniej z całego zbioru?\n",
    "\n",
    "- TP high plus atr, distance = 3,6,12\n",
    "+ ograniczyć zbiór kolumn wejściowych tylko do historii daily,weekly,monthly DWM\n",
    "- trenować jeden model na kilku walutach - historia DWM (/avgatr)\n",
    "\n",
    "Eksperymenty:\n",
    "hh_n1 higher high next day\n",
    "loc - lokalnie\n",
    "az - azure notebooks\n",
    "hh_n1_post_loc - masterframe przygotowany na podstawie danych źródłowych z ducasopy z tego samego okresu co pre, są pewne różnice: pewnych dni nie ma, niektóre kursy się róźnią, data split obserwacje losowo\n",
    "hh_n1_pre_az - to samo co wyżej\n",
    "hh_n1_post_az - to samo co wyżej\n",
    "hh_n1_post_az_test - masterframe przygotowany na podstawie danych źródłowych, które powstały z masterframa_pre - aby mieć te same dni oraz te same kursy, masterframe przycięty do 3600, data split po kolei, fourier log_close-log_close\n",
    "hh_n1_pre_az_test - masterframe przycięty do 3600 obserwacji, data split obserwacje po kolei GARCH/ARIMA 0,1,0\n",
    "hh_n1_post_az_test2 - to samo co test ale fourier: close - close GARCH/ARIMA 0,1,0\n",
    "hh_n1_post_az_test3 - garch 3,0,1\n",
    "test4 - garch 3,1,0\n",
    "Wniosek jest taki, że garch nie ma decudującego znaczenia. FeatureCreation POST (po incydencie) można uznać, że jest taki jak PRE (Przed incydentem) !!!!!!\n",
    "**higher high next day**\n",
    "test5 - to co test4, plus usunięty błąd w MLP [10,10] - samo MLP z timeoutem\n",
    "test6 - MLP bez timeoutów\n",
    "test7 - wszystkie modele, feature_data przetworzone z danych oryg (bez przycięcia do 3600), split po kolei, MLP z timeoutem 5min, przycięte parametry (bez adam, 'identity', 'logistic', bez 100 iter),\n",
    "\n",
    "Wnioski z eksperymentów\n",
    "- na masterframe przed - split random gorszy niż po kolei\n",
    "\n",
    "***Data v10\n",
    "- bez historii DWM 30\n",
    "Data v10a\n",
    "- same ficzery\n",
    "- bez historii DWM 30\n",
    "- poprawione atr: dodane avgtr - potrzebne do przygotowania y \n",
    "Dane v10b\n",
    "- slope w stopniach znormalizowane do 0-1\n",
    "- bez adosc\n",
    "- wszystkie ficzery znormalizowane\n",
    "Dane v10c\n",
    "- poprawiony numer dnia\n",
    "\n",
    "Data v13\n",
    "- zawiera historię D W M 30\n",
    "****Dane v14\n",
    "- all - ficzery plus historia\n",
    "- history div avgatr\n",
    "np. df[columnname_hist_diff] = df[columnname_hist_diff] / avgtr\n",
    "Dane v14a\n",
    "uporządkowana historia (tak jak w 16a)\n",
    "Dane v14b\n",
    "- slope w stopniach znormalizowane do 0-1\n",
    "- bez adosc\n",
    "- wszystkie ficzery znormalizowane\n",
    "- historia DWM uporządkowana\n",
    "Dane v14c\n",
    "- poprawiony numer dnia\n",
    "\n",
    "Dane v15\n",
    "+ sama historia DWM\n",
    "***Dane v16\n",
    "+ sama historia DWM\n",
    "+ zostawić naprawdę tylko historię: przerobiłem na różnice do close podzielić na avgtr, weekId i mounthid oraz close usunąłem\n",
    "hW130weekID\thW130W1high_c\thW130W1low_c\thW130W1close_c\thW130W1open_c\n",
    "hM130monthID\thM130M1high_c\thM130M1low_c\thM130M1close_c\thM130M1open_c\n",
    "\n",
    "Dane v16a 2021-02-9 Kolejna wersja danych\n",
    "uporządkowanie kolejności: low, high, close\n",
    "low_c,high_c,close_c na końcu\n",
    "close_c=0\n",
    "\n",
    "Dane v16b\n",
    "bez ficzera atr (wyliczany w model_hyper)\n",
    "Dane v16c\n",
    "poprawiłem date = +1 dzień - ma to wpływ na numer tygodnia\n",
    "\n",
    "Testy:\n",
    "**SL low minus atr, TP high plus atr, distanse 5**\n",
    "+test8 - dane v10, SL low minus atr, TP high plus atr, distanse 5\n",
    "+test9 - stary test (sprzed incydentu) pre_azure_closeplusminus1ATR_next5 - chain\n",
    "+test10 - to samo co test9 ale na aktualnych skryptach - tylko svc 15 MLP - chain - colab\n",
    "+test11 - to samo co test 10 plus SMOTE - local\n",
    "+test12 - dane v13, SL low minus atr, TP high plus atr, distanse 5, colab, SMOTE sampling_strategy='majority'\n",
    "+test13 - test12 + SMOTE sampling_strategy='not minority'\n",
    "Wychodzi na to, że test12 lepszy niż test13\n",
    "\n",
    "**SL low minus atr, TP high plus atr, distanse infinity, SMOTE sampling_strategy='majority'**\n",
    "+test14_14 - dane v14, SL low minus atr, TP high plus atr, distanse infinity, SMOTE sampling_strategy='majority' azure\n",
    "+do wyjaśnienia\n",
    "v14_rf45_SVC1590196531 sort by Te_1_80 (75.8)\n",
    "C\tgamma\tkernel\tdegree\n",
    "10.0\tauto\tpoly\t2.0\n",
    "+ dlaczego nie ma równowagi między jedynkami a zerami Te_1_cnt jest 47,4.- wyrównanie balansu klas jest tylko dla zbioru train\n",
    "+ dlaczego Te_0_50_cnt jest 10 a Te_1_50_cnt  jest 90. Sprawdziłem i rzeczywiście model daje>0.5 dla 90% rekordów\n",
    "+test14_15 - dane v15, SL low minus atr, TP high plus atr, distanse infinity, SMOTE sampling_strategy='majority'\n",
    "\n",
    "+ Do wyjaśnienia: dlaczego procenty przy 0.9 są większe niż przy 0.8. Odp. To są po prostu inne modele.\n",
    "\n",
    "Pomysł: y=1 w danych wejściowych tylko tam gdzie model zgadł z pewnością np.0.7. W pozostałych przypadkach dać 0. Najwyżej będzie źle zgadywał 0, ale zero oznacza, że nie wchodzę do trade'u. Zrobić to tylko na zbiorze treningowym. \n",
    "\n",
    "**SL low minus atr, TP high plus atr, distanse infinity, SMOTE sampling_strategy='majority'**\n",
    "+test14_10a - dane v10a(bez DWM30), SL low minus atr, TP high plus atr, distanse infinity, SMOTE sampling_strategy='majority'\n",
    "\n",
    "test14_14 vs test14_15 vs test14_10a - ten sam kod trenowania/testowania:\n",
    "dane14(ficzery + DWM), dane15(DWM), dane10a(ficzery)  \n",
    "\n",
    "w kodzie usunąłem: id  atr14tr\tatr14atr\tatr14avgtr\n",
    "fulldate\tyear\tmonth\tday\topen\thigh\tlow\tclose\n",
    "\n",
    "+test17_10a - dane v10a ficz\n",
    "\n",
    "+test17_14 - dane v14 data all\n",
    "podczas all MLP\n",
    "C:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
    "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "\n",
    "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
    "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
    "\n",
    "-test17_16 - dane v16 DWM\n",
    "\n",
    "+ Zrobić porównanie która metoda wyboru feature sel jest najgorsza i wyeliminować, to samo dla liczby featurów oraz rodzaju modelu\n",
    "w teście 14 i 17 randfor jest najsłabszy\n",
    "\n",
    "+ zapuścić fastai i porównać z pozostałymi\n",
    "+ przyjrzeć się pojedynczemu przypadkowi modelu - popatrzeć na wykres czy to ma sens\n",
    "\n",
    "+ usunął atr slope\n",
    "+ zmienić kolejność: hW130W1high_c\thW130W1low_c\thW130W1open_c. Powinno być po danych W1, zamienić hW130W1open_c na close czyli 0,\n",
    "+ to samo tylko dla M1, dla D1 jest chyba OK\n",
    "+ poprawić minmax scaler - dać na cały dataframe a nie tylko w ramach kolumn - chyba NN też trzeba poprawić, nie wiem jak działa Normalize\n",
    "+ sprawdzić czy kolumny są w tej samej kolejności: close,low,high - może zmienić na low,high,close?\n",
    "- metrics Precision być może daje lepsze wyniki niż accuracy dla NN\n",
    "- czy uzupełniąc nulle historii M1 i W1 - np. pierwszymi wartościami w historii??\n",
    "+ dorobić scaler dla v14 oraz v16\n",
    "- todo: all data, simple y, obrazki(ważne skalowanie)\n",
    "- todo: historię H4 albo H1\n",
    "\n",
    "2020-02-09\n",
    "Zmieniłem kod - atr\n",
    "przekazuje do prepare_y atr\n",
    "atr = masterframe.atr14tr.mean() - średnia z całego zbioru danych\n",
    "wcześniej wewnątrz prepare_y brał z kolumny avgtr, która w sumie miała tę samą wart dla całego zbioru (więc to bez zmiam) \n",
    "przekazuję również atr do wszystkich examine. To zmiana kosmetyczna - wcześnie ta średnia była wyliczana wewnątrz funkcji\n",
    "2020-02-09\n",
    "dodałem kod, że gdy wersja danych == v16 wtedy usuwam wszystkie kolumny związane z atr\n",
    "\n",
    "2020-02-10\n",
    "poprawiłem slope - dałem w radianach\n",
    "usunąłem adosc bo on bazuje na volume i daje kosmiczne liczby.\n",
    "jestem w trakcie generowania nowych wersji danych - wersje b\n",
    "\n",
    "2020-02-11\n",
    "dodałem kod wyliczający atr w model_hyper - nie jest wymagany w danych 16, może być znormalizowane w danych\n",
    "skalowanie ficzerów w danych - w kodzie brak skalowania.\n",
    "- test 18_10b\n",
    "\n",
    "2020-02-12\n",
    "w feature collection poprawiłem dzień - plus jeden - miało to wpływ na numer tygodnia -dane ver c\n",
    "dane wersje c\n",
    "usunąłem z ExamineNN catnames= y - to dawało acc=100;-)\n",
    "zmieniłem na random split daje lepsze wyniki niż nie-random\n",
    "\n",
    "\n",
    "2020-02-12\n",
    "dodałem w kodzie skalowanie historii dla v14 i v16, Normalize w NN zostaje bo tak są lepsze wyniki\n",
    "zmieniłem split na nie-random - aby było jednolicie z poprzednimi testami\n",
    "\n",
    "2020-02-17\n",
    "usunąłem kod usuwający kolumny OLHC - zamiast tego skaluję together\n",
    "\n",
    "2020-02-17\n",
    "zrobiłem porządki tak aby wyniki testu 18 były takie same lub lepsze niż 17\n",
    "przywróciłem skalowanie minmax (także dla historii)\n",
    "kolumny OLHC są usuwane\n",
    "\n",
    "2020-02-17 Test_19_16c\n",
    "2020-02-22 Test_19_14c\n",
    "2020-02-25 Test_19_10c\n",
    "\n",
    "Test20\n",
    "distance 3; high+1atr\n",
    "NN\n",
    "SVC\n",
    "2020-03-03\n",
    "- poprawka do undersampling - teraz jest na cały masterframe a nie tylko na X_train. To ma największy wpływ na NN bo wcześniej nie było balansu ani w test ani w train. Dla pozostałych np. svc też ma wpływ ale tylko na kalkulację test_accuracy. Niestety undersampling zmniejsza ilość danych do trenowania\n",
    "\n",
    "Test21\n",
    "distance 3: high+1atr\n",
    "NN SVC\n",
    "Test22\n",
    "distance 1: high+1atr\n",
    "NN SVC\n",
    "Test23\n",
    "distance 5: high+1atr\n",
    "Test24\n",
    "distance 1: high+0.5atr\n",
    "\n",
    "2020-03-05\n",
    "Poprawiłem, aby była możliwośc undersample tylko train bez test - dla NN\n",
    "poprzednio wszystko było undersample\n",
    "a jeszcze wcześniej undersample tylko train nie działało dla NN\n",
    "\n",
    "Test25\n",
    "7majors dis1 high+1atr\n",
    "undersample train and test\n",
    "\n",
    "2021-03-06\n",
    "poprawka do pokazywania statystyk\n",
    "2021-03-08\n",
    "poprawka do sortowania przy sklejaniu train and test\n",
    "\n",
    "Test26\n",
    "7majors dis1 high+1atr\n",
    "undersample train\n",
    "\n",
    "2020-03-09\n",
    "wycofanie poprawki do statystyk\n",
    "wycofanie sortowania testdf po undersample - bo musi być ta sama kolejność co w Xintex\n",
    "\n",
    "2020-03-10\n",
    "Zrobiłem próbę z SMOTE, overall accuracy lepsze ale jedynki gorzej klasyfikuje\n",
    "\n",
    "2020-02-12\n",
    "dołożyłem trochę więcej opcji parametrów NN\n",
    "\n",
    "Test 27\n",
    "7majors dis1 high+1atr\n",
    "undersample train\n",
    "\n",
    "Test 28\n",
    "7majors dis1 high+1atr\n",
    "SMOTE train\n",
    "\n",
    "Test 29\n",
    "7majors dis1 high+1atr\n",
    "oversample train\n",
    "\n",
    "following close > high+atr\n",
    "accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Test 32\n",
    "7majors dis2 high+1atr\n",
    "SMOTE train\n",
    "\n",
    "Test 33\n",
    "7majors dis3 high+1atr\n",
    "SMOTE train\n",
    "\n",
    "Test 34\n",
    "7majors dis4 high+1atr\n",
    "SMOTE train\n",
    "\n",
    "Test 35\n",
    "7majors dis5 high+1atr\n",
    "SMOTE train\n",
    "\n",
    "\n",
    "\n",
    "Test 41\n",
    "7majors dis1 high+2atr\n",
    "SMOTE train\n",
    "\n",
    "Test 42\n",
    "7majors dis2 high+2atr\n",
    "SMOTE train\n",
    "\n",
    "Test 43\n",
    "7majors dis3 high+2atr\n",
    "SMOTE train\n",
    "\n",
    "Test 44\n",
    "7majors dis4 high+2atr\n",
    "SMOTE train\n",
    "\n",
    "Test 45\n",
    "7majors dis5 high+2atr\n",
    "SMOTE train\n",
    "\n",
    "\n",
    "\n",
    "Test 51\n",
    "7majors dis1 high+3atr\n",
    "SMOTE train\n",
    "\n",
    "Test 52\n",
    "7majors dis2 high+3atr\n",
    "SMOTE train\n",
    "\n",
    "Test 53\n",
    "7majors dis3 high+3atr\n",
    "SMOTE train\n",
    "\n",
    "Test 54\n",
    "7majors dis4 high+3atr\n",
    "SMOTE train\n",
    "\n",
    "Test 55\n",
    "7majors dis5 high+3atr\n",
    "SMOTE train\n",
    "\n",
    "\n",
    "Test 61\n",
    "7majors dis1 high+4atr\n",
    "SMOTE train\n",
    "\n",
    "Test 62\n",
    "7majors dis2 high+4atr\n",
    "SMOTE train\n",
    "\n",
    "Test 63\n",
    "7majors dis3 high+4atr\n",
    "SMOTE train\n",
    "\n",
    "Test 64\n",
    "7majors dis4 high+4atr\n",
    "SMOTE train\n",
    "\n",
    "Test 65\n",
    "7majors dis5 high+4atr\n",
    "SMOTE train\n",
    "\n",
    "\n",
    "Test 71\n",
    "7majors dis1 high+5atr\n",
    "SMOTE train\n",
    "\n",
    "Test 72\n",
    "7majors dis2 high+5atr\n",
    "SMOTE train\n",
    "\n",
    "Test 73\n",
    "7majors dis3 high+5atr\n",
    "SMOTE train\n",
    "\n",
    "Test 74\n",
    "7majors dis4 high+5atr\n",
    "SMOTE train\n",
    "\n",
    "Test 75\n",
    "7majors dis5 high+5atr\n",
    "SMOTE train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
